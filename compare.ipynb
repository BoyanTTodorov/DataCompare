{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Invoice nr Kostenplaats site   Naam Medewerker  Personeels nummer  \\\n",
      "0           NaN               NaN               NaN                NaN   \n",
      "3    95290085.0         GXO Venlo  Adrian Ciobanita           388412.0   \n",
      "4    95290085.0         GXO Venlo  Adrian Ciobanita           388412.0   \n",
      "6           NaN               NaN               NaN                NaN   \n",
      "7           NaN               NaN               NaN                NaN   \n",
      "..          ...               ...               ...                ...   \n",
      "747         NaN               NaN               NaN                NaN   \n",
      "752         NaN               NaN               NaN                NaN   \n",
      "753         NaN               NaN               NaN                NaN   \n",
      "754  95290085.0         GXO Venlo      Zyta Dlugosz           339973.0   \n",
      "757  95290085.0         GXO Venlo      Zyta Dlugosz           339973.0   \n",
      "\n",
      "      Toeslag       Date  Gewerkte week  Agency hours (minutes)  \\\n",
      "0         NaN        NaT            NaN                     0.0   \n",
      "3           1 2024-09-09           37.0                   388.8   \n",
      "4        1.45 2024-09-09           37.0                    60.0   \n",
      "6         NaN        NaT            NaN                     0.0   \n",
      "7         NaN        NaT            NaN                     0.0   \n",
      "..        ...        ...            ...                     ...   \n",
      "747       NaN        NaT            NaN                     0.0   \n",
      "752       NaN        NaT            NaN                     0.0   \n",
      "753       NaN        NaT            NaN                     0.0   \n",
      "754         1 2024-09-13           37.0                   465.0   \n",
      "757  130% ovw 2024-09-13           37.0                    15.0   \n",
      "\n",
      "     Subtotaal excl Reiskosten  Nettowaarde  ...  Scale+Step  Base Wage  \\\n",
      "0                          NaN          NaN  ...         NaN        NaN   \n",
      "3                       167.18       167.41  ...         NaN        NaN   \n",
      "4                        36.18        36.18  ...         NaN        NaN   \n",
      "6                          NaN          NaN  ...      GXO4-0      13.68   \n",
      "7                          NaN          NaN  ...      GXO4-0      13.68   \n",
      "..                         ...          ...  ...         ...        ...   \n",
      "747                        NaN          NaN  ...      GXO3-3      13.68   \n",
      "752                        NaN          NaN  ...      GXO4-0      13.68   \n",
      "753                        NaN          NaN  ...      GXO3-0      13.68   \n",
      "754                     193.83       201.88  ...      GXO3-3      13.68   \n",
      "757                       6.29         6.29  ...      GXO3-3      13.68   \n",
      "\n",
      "       Phase ORF-Rate Hourly Rate Invoice incl ADV Week_Number_y      _merge  \\\n",
      "0        NaN      NaN         NaN    141864.267862           NaN  right_only   \n",
      "3        NaN      NaN         NaN              NaN           NaN   left_only   \n",
      "4        NaN      NaN         NaN              NaN           NaN   left_only   \n",
      "6    Phase B   1.8283   25.011144       162.155584      2024-W36  right_only   \n",
      "7    Phase B   1.6345   35.073126        35.073126      2024-W36  right_only   \n",
      "..       ...      ...         ...              ...           ...         ...   \n",
      "747  Phase B   1.8274   24.998832       199.990656      2024-W36  right_only   \n",
      "752  Phase A   1.8274   24.998832       199.990656      2024-W36  right_only   \n",
      "753  Phase A   1.8274   24.998832       174.991824      2024-W36  right_only   \n",
      "754  Phase C   1.4144   25.153690         6.288422      2024-W36        both   \n",
      "757  Phase C   1.8283   25.011144       193.836366      2024-W36        both   \n",
      "\n",
      "    Hours Difference (minutes)        Source  \n",
      "0                    -340442.0  Protime Only  \n",
      "3                        388.8   Agency Only  \n",
      "4                         60.0   Agency Only  \n",
      "6                       -389.0  Protime Only  \n",
      "7                        -60.0  Protime Only  \n",
      "..                         ...           ...  \n",
      "747                     -480.0  Protime Only  \n",
      "752                     -480.0  Protime Only  \n",
      "753                     -420.0  Protime Only  \n",
      "754                      450.0      Mismatch  \n",
      "757                     -450.0      Mismatch  \n",
      "\n",
      "[398 rows x 33 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\boyan.todorov\\Desktop\\PDFCOMPARE\\venv\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "C:\\Users\\boyan.todorov\\AppData\\Local\\Temp\\ipykernel_16068\\1217478499.py:54: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['Agency hours'].fillna(0, inplace=True)\n",
      "C:\\Users\\boyan.todorov\\AppData\\Local\\Temp\\ipykernel_16068\\1217478499.py:55: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['GXO Hours'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Assign paths\n",
    "path_protime = r'./Protime'\n",
    "path_agency = r'./Agency'\n",
    "\n",
    "# List files in directories\n",
    "folder_protime = os.listdir(path_protime)\n",
    "folder_agency = os.listdir(path_agency)\n",
    "\n",
    "def concat_data(path, folder, file_extension=None, starts_with=None):\n",
    "    # Filter files based on extension and starting name\n",
    "    filtered_files = [file for file in folder if (file_extension is None or file.endswith(file_extension))]# and (starts_with is None or file.startswith(starts_with))]\n",
    "    \n",
    "    # Concatenate files or read single file\n",
    "    if len(filtered_files) > 1:\n",
    "        df = pd.concat([pd.read_excel(os.path.join(path, file)) for file in filtered_files])\n",
    "    elif len(filtered_files) == 1:\n",
    "        df = pd.read_excel(os.path.join(path, filtered_files[0]))\n",
    "    else:\n",
    "        df = pd.DataFrame()  # Return an empty DataFrame if no files match\n",
    "    return df\n",
    "\n",
    "# Load data\n",
    "agency = concat_data(path_agency, folder_agency, '.xlsx')\n",
    "protime = concat_data(path_protime, folder_protime, '.xlsx')\n",
    "\n",
    "# Ensure correct date format and calculate week number\n",
    "agency['Datum'] = pd.to_datetime(agency['Datum'])\n",
    "agency['Week_Number'] = agency['Datum'].dt.strftime('%Y-W%U')\n",
    "\n",
    "protime['Date'] = pd.to_datetime(protime['Date'])\n",
    "protime['Week_Number'] = protime['Date'].dt.strftime('%Y-W%U')\n",
    "\n",
    "# Rename columns for clarity\n",
    "agency = agency.rename(columns={'Uren': 'Agency hours'})\n",
    "protime = protime.rename(columns={'Hours (Dec)': 'GXO Hours'})\n",
    "\n",
    "# Aggregate data by date and employee name\n",
    "agency_aggregated = agency.groupby(['Naam Medewerker','Datum'])['Agency hours'].sum().reset_index()\n",
    "protime_aggregated = protime.groupby(['Full Name', 'Date'])['GXO Hours'].sum().reset_index()\n",
    "\n",
    "# print(agency_aggregated.head())\n",
    "# print(protime_aggregated.head())\n",
    "\n",
    "# Merging based on dates and employee names\n",
    "merged_df = pd.merge(agency, protime, \n",
    "                     left_on=['Datum', 'Naam Medewerker'], \n",
    "                     right_on=['Date', 'Full Name'], \n",
    "                     how='outer', indicator=True)\n",
    "\n",
    "# Fill NaN values with 0 to handle missing data from the outer merge\n",
    "merged_df['Agency hours'].fillna(0, inplace=True)\n",
    "merged_df['GXO Hours'].fillna(0, inplace=True)\n",
    "\n",
    "# Convert hours to minutes\n",
    "merged_df['Agency hours'] = merged_df['Agency hours'] * 60\n",
    "merged_df['GXO Hours'] = merged_df['GXO Hours'] * 60\n",
    "\n",
    "# Create a column to check if the minutes match\n",
    "merged_df['Hours_Difference'] = merged_df['Agency hours'] - merged_df['GXO Hours']\n",
    "\n",
    "# Add a column to check the source of the difference\n",
    "merged_df['Source'] = merged_df.apply(\n",
    "    lambda row: 'Agency Only' if row['_merge'] == 'left_only' else (\n",
    "                'Protime Only' if row['_merge'] == 'right_only' else (\n",
    "                'Mismatch' if row['Hours_Difference'] != 0 else 'Match')),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Filter rows where there is a mismatch or a missing value in one of the datasets\n",
    "diff_df = merged_df[merged_df['Source'] != 'Match']\n",
    "\n",
    "# Exclude rows where the difference is less than 2 minutes\n",
    "diff_df = diff_df[diff_df['Hours_Difference'].abs() >= 2]\n",
    "\n",
    "# Rename columns with units for clarity\n",
    "diff_df.rename(columns={\n",
    "    'Datum': 'Date',\n",
    "    'Agency hours': 'Agency hours (minutes)',\n",
    "    'GXO Hours': 'GXO Hours (minutes)',\n",
    "    'Hours_Difference': 'Hours Difference (minutes)'\n",
    "}, inplace=True)\n",
    "\n",
    "# Display the rows with discrepancies and the source\n",
    "print(diff_df)\n",
    "\n",
    "# Save the results to an Excel file\n",
    "diff_df.to_excel('Long_Report.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: Uren'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m agency_aggregated \u001b[38;5;241m=\u001b[39m \u001b[43magency\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDatum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUren\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      2\u001b[0m protime_aggregated \u001b[38;5;241m=\u001b[39m protime\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHours (Dec)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(agency_aggregated\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Users\\boyan.todorov\\Desktop\\PDFCOMPARE\\venv\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1951\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1945\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[0;32m   1946\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1950\u001b[0m     )\n\u001b[1;32m-> 1951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\boyan.todorov\\Desktop\\PDFCOMPARE\\venv\\Lib\\site-packages\\pandas\\core\\base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Column not found: Uren'"
     ]
    }
   ],
   "source": [
    "\n",
    "agency_aggregated = agency.groupby(['Datum'])['Uren'].sum().reset_index()\n",
    "protime_aggregated = protime.groupby(['Date'])['Hours (Dec)'].sum().reset_index()\n",
    "\n",
    "print(agency_aggregated.head())\n",
    "print(protime_aggregated.head())\n",
    "\n",
    "# Merging based on dates and employee names\n",
    "merged_df = pd.merge(agency_aggregated, protime_aggregated, \n",
    "                     left_on=['Datum', 'Naam Medewerker'], \n",
    "                     right_on=['Date', 'Full Name'], \n",
    "                     how='outer', indicator=True)\n",
    "\n",
    "# Fill NaN values with 0 to handle missing data from the outer merge\n",
    "merged_df['Uren'].fillna(0, inplace=True)\n",
    "merged_df['Hours (Dec)'].fillna(0, inplace=True)\n",
    "\n",
    "# Create a column to check if the hours match\n",
    "merged_df['Hours_Difference'] = merged_df['Uren'] - merged_df['Hours (Dec)']\n",
    "\n",
    "# Add a column to check the source of the difference\n",
    "merged_df['Source'] = merged_df.apply(\n",
    "    lambda row: 'Agency Only' if row['_merge'] == 'left_only' else (\n",
    "                'Protime Only' if row['_merge'] == 'right_only' else (\n",
    "                'Mismatch' if row['Hours_Difference'] != 0 else 'Match')),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Filter rows where there is a mismatch or a missing value in one of the datasets\n",
    "diff_df = merged_df[merged_df['Source'] != 'Match']\n",
    "\n",
    "# Drop unnecessary columns for cleaner output\n",
    "diff_df = diff_df.drop(columns=['_merge', 'Date', 'Full Name'])\n",
    "\n",
    "# Display the rows with discrepancies and the source\n",
    "print(diff_df)\n",
    "\n",
    "diff_df.to_excel('Long_Report.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Datum    Naam Medewerker  Uren  Hours (Dec)  Hours_Difference\n",
      "2024-09-02     Roksana Kubala   8.0         4.75              3.25\n",
      "2024-09-03       Marcin Dudek   8.0         7.97              0.03\n",
      "2024-09-06 Anisoara Cimpoiesu   8.0         7.40              0.60\n",
      "2024-09-06       Marcin Dudek   8.0         7.93              0.07\n",
      "2024-09-06  Orlando Hernandez   8.0         6.13              1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boyan.todorov\\AppData\\Local\\Temp\\ipykernel_14080\\2613005928.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diff_df['Datum'] = pd.to_datetime(diff_df['Datum']).dt.strftime('%Y-%m-%d')\n",
      "C:\\Users\\boyan.todorov\\AppData\\Local\\Temp\\ipykernel_14080\\2613005928.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diff_df['Hours (Dec)'] = diff_df['Hours (Dec)'].round(2)\n",
      "C:\\Users\\boyan.todorov\\AppData\\Local\\Temp\\ipykernel_14080\\2613005928.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diff_df['Hours_Difference'] = diff_df['Hours_Difference'].round(2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "agency_aggregated = agency.groupby(['Datum', 'Naam Medewerker'])['Uren'].sum().reset_index()\n",
    "protime_aggregated = protime.groupby(['Date', 'Full Name'])['Hours (Dec)'].sum().reset_index()\n",
    "\n",
    "# Merging the two DataFrames based on dates and employee names (inner join to match both)\n",
    "merged_df = pd.merge(agency_aggregated, protime_aggregated, \n",
    "                     left_on=['Datum', 'Naam Medewerker'], \n",
    "                     right_on=['Date', 'Full Name'], \n",
    "                     how='inner')  # Only keep rows that exist in both datasets\n",
    "\n",
    "# Create a column to check the difference in hours\n",
    "merged_df['Hours_Difference'] = merged_df['Uren'] - merged_df['Hours (Dec)']\n",
    "\n",
    "# Filter rows where the difference is greater than 2 minutes (0.0333 hours)\n",
    "diff_df = merged_df[abs(merged_df['Hours_Difference']) > 0.0333]\n",
    "\n",
    "# Format the 'Datum' column to remove the time and display only the date\n",
    "diff_df['Datum'] = pd.to_datetime(diff_df['Datum']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Round the decimal values for hours to 2 decimal places for better readability\n",
    "diff_df['Hours (Dec)'] = diff_df['Hours (Dec)'].round(2)\n",
    "diff_df['Hours_Difference'] = diff_df['Hours_Difference'].round(2)\n",
    "\n",
    "# Drop unnecessary columns for cleaner output\n",
    "diff_df = diff_df.drop(columns=['Date', 'Full Name'])\n",
    "\n",
    "# Display the rows with significant discrepancies in a table format\n",
    "print(diff_df.to_string(index=False))\n",
    "\n",
    "diff_df.to_excel('Short_Report.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
